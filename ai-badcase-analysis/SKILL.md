---
name: ai-badcase-analysis
description: "[AI产品Badcase分析指导] [AI Product Badcase Analysis Guide] 帮助用户系统化分析、定位和解决AI产品中的badcase问题。提供从现状评估、问题分析到解决方案的全流程方法论支持、思维引导和checklist。适用于：(1) AI产品出现预测错误或效果不佳时 (2) 需要系统化分析模型失败案例时 (3) 优化算法效果但不知从何入手时 (4) 需要建立badcase分析工作流程时。本技能提供指导性建议和方法论，不直接处理badcase数据。"
---

# AI产品Badcase分析指导

## 概述

本技能提供一套完整的AI产品Badcase分析方法论，帮助用户系统化地定位、分析和解决AI模型预测错误问题。技能采用指导性方式，通过提供思维框架、检查清单和方法论支持，引导用户完成badcase分析工作。

**核心价值：**
- 提供系统化的分析流程（现状评估 → 问题分析 → 解决方案）
- 提供思维引导和检查清单，避免遗漏关键步骤
- 帮助建立正确的分析思路，而非直接处理数据

## 工作流程

Badcase分析遵循四个阶段：**认知建立 → 现状评估 → 问题分析 → 解决方案**

### 阶段1：认知建立

在开始分析前，建立对badcase的正确认知：

- **什么是badcase**：推理阶段产生的与预期不同的结果
- **分析意义**：badcase是问题症状，通过分析能找到病因
- **心理准备**：分析50-100条即可说明问题，时间成本可控

**检查清单：**
- [ ] 是否理解badcase是正常现象（人类也会出错）？
- [ ] 是否明确分析badcase的核心价值（症状诊断、经验积累）？
- [ ] 是否准备好投入10-30分钟进行分析？

详细方法论见 [references/methodology.md](references/methodology.md) 的"认知篇"部分。

### 阶段2：现状评估

**关键原则：** 必须先明确现状，才能确定优化方向。不要发现一个badcase就立即修复。

#### 2.1 评测集检查

评估当前使用的评测集是否可靠：

**检查清单：**
- [ ] 数据集是否具有完整意义（不是一两条case）？
- [ ] 数量是否足够支撑指标计算稳定（建议100+条）？
- [ ] 抽样情况是否与实际使用场景一致？
- [ ] 数据质量是否可靠（自己标注100条验证，准确率95%+为佳）？

**常见问题：**
- 开源数据集可能有标注错误
- 准确率到90%上不去，可能是评测集问题
- 不要为提升几个点而高兴，先检查数据质量

#### 2.2 指标设计检查

评估指标设计是否合理：

**检查清单：**
- [ ] 指标是否体现观测目标（如避免误召回）？
- [ ] 指标口径是否明确（不同条件取数据可能结论不同）？
- [ ] 是否组合多个指标观测（准确率+召回率）？

**关键提醒：**
- 准确率优化时，召回率可能降低
- 需同时看准确率和召回率，两者平衡提升才健康

#### 2.3 现状结论

基于评测集和指标，得出结论：

**检查清单：**
- [ ] 算法效果好or不好？（与预期目标对比）
- [ ] 是否需要进一步优化？
- [ ] 优化方向是什么？（优化准确率、扩大召回等）

**关键提醒：**
- 明确预期目标（如准召80%+）
- 下结论时要顾及下一步工作
- 要有模糊方向，知道哪些badcase是关键

详细方法论见 [references/methodology.md](references/methodology.md) 的"现状篇"部分。

### 阶段3：问题分析

基于现状评估确定的优化方向，系统化分析badcase。

#### 3.1 样本选择

**检查清单：**
- [ ] 是否结合现状分析确定了要优化的方面（准确率/召回率）？
- [ ] 样本数量是否足够（建议50-200个）？
- [ ] 是否采用随机抽样（非随机可能导致主干问题不出现在样本中）？

#### 3.2 分析方法选择

根据情况选择合适的分析方法：

**粗看法**（快速找大问题）：
- 适用：baseline刚建立，效果未收敛时
- 方法：笼统看错误样本的共同特点（长度、句式、问句等）
- 检查清单：
  - [ ] 是否关注了长度、句式、问句等特征？
  - [ ] 是否总结了突出问题？

**追溯法**（找单个case核心原因）：
- 适用：需要深入分析单个case时
- 方法：重现整个训练和预测过程，检查训练样本、正负样本比例
- 检查清单：
  - [ ] 是否准备了日志，分析预测每个阶段的结果？
  - [ ] 是否去训练样本查找是否含有类似badcase？
  - [ ] 是否检查了正负样本比例是否失衡？

**解决法**（反向思考）：
- 适用：知道有哪些解决方法时
- 方法：反向思考，看badcase是否可用已知方式解决
- 检查清单：
  - [ ] 是否把问题归纳到对应解决方案上？

#### 3.3 问题标记和统计

**标记要求：**
- [ ] 是否对每个case做了关键记录（归因、解决方案）？
- [ ] 词汇和问题是否统一，方便统计占比？
- [ ] 一个问题是否有多个解决方法，是否都标记了？

**统计分析：**
- [ ] 是否统计了各问题分布情况？
- [ ] 是否识别了重点问题（占比高的问题）？
- [ ] 是否评估了重点问题的解决价值（占比50%的问题，完全解决可提升20%准确率）？

详细方法论和示例见 [references/methodology.md](references/methodology.md) 的"分析篇"部分。

### 阶段4：解决方案

基于问题分析结果，实施针对性解决方案。

#### 4.1 解决方案选择

**核心原则：** 大多数问题不在模型本身，换模型带来的收益可能很小。

**方案1：样本的误导**
- **识别**：badcase中从句子层面发现明显共性的，大概率是这个问题
- **解决**：调整数据，平衡正负样本关系
- **检查清单：**
  - [ ] 是否识别出数据中浅层直白的信息误导了模型？
  - [ ] 是否添加了带误导性特征的负样本？

**方案2：阈值的确定和权衡**
- **本质**：准召的权衡
- **方法**：对标准召做权衡，确定最佳阈值
- **检查清单：**
  - [ ] 是否准备了标注数据用于阈值实验？
  - [ ] 是否测试了不同阈值下的准确率和召回率？
  - [ ] 是否根据业务场景确定了最佳阈值（搜索对话场景一般0.85+）？

**方案3：前后处理和预处理**
- **预处理**：去掉对预测有影响的干扰项
- **前处理**：模型预测之前的过滤（黑白名单、业务规则）
- **后处理**：模型预测后的调整（阈值过滤、关键词抽取、实体约束）
- **检查清单：**
  - [ ] 是否识别了干扰项（看badcase，错误样本会告诉你）？
  - [ ] 是否考虑了前处理（能用规则尽量用规则）？
  - [ ] 是否考虑了后处理（模型难学习的东西通过后处理修复）？

#### 4.2 验证和迭代

**流程检查清单：**
- [ ] 是否重跑验证集，看修复后效果？
- [ ] 是否回到第一步：现状确认？
- [ ] 是否重新确定是否还要优化？
- [ ] 如需优化，是否继续badcase分析？

**关键提醒：**
- 老问题不解决，新问题暴露不出来
- 随着问题逐步解决，很多问题会从主要问题变成次要问题
- 问题千千万，但随着解决，总会朝着目标靠近

#### 4.3 换模型时机判断

**检查清单：**
- [ ] 是否能看到当前方案的天花板？
- [ ] 天花板标志：
  - [ ] 很多零散的badcase
  - [ ] 问题不太能总结出来
  - [ ] 总结出来发现分布很均匀，每个只错一两条
- [ ] 是否靠修补提升不了效果了？

**关键提醒：**
- 换模型的本质不在提升效果，而是算法系统预测能力上限的提升
- SOTA是特定数据集的SOTA，是否适合你要多想想
- 靠修补提升不了效果时，才靠模型进一步探索

详细方法论见 [references/methodology.md](references/methodology.md) 的"解决篇"部分。

## 快速参考

### 完整方法论文档

详细的方法论、示例和注意事项见：
- [references/methodology.md](references/methodology.md) - 完整的方法论（认知篇、现状篇、分析篇、解决篇）

### 检查清单汇总

各阶段检查清单已整合在工作流程中，也可参考：
- [references/checklist.md](references/checklist.md) - 所有检查清单的汇总

## 使用建议

1. **首次使用**：先阅读完整的方法论文档，建立对badcase分析的全面认知
2. **实际分析**：按照工作流程的四个阶段逐步进行，使用检查清单确保不遗漏关键步骤
3. **遇到问题**：回到对应阶段的方法论文档，查找详细说明和示例
4. **持续优化**：遵循验证和迭代流程，螺旋上升

## 注意事项

- **不要跳过现状评估**：发现一个badcase就去修，很可能会导致新问题出现
- **数量要足够**：50-100条即可说明问题，太少可能影响判断
- **必须随机抽样**：非随机可能导致主干问题不出现在样本中
- **问题要统计**：通过统计占比找到重点问题，重点问题解决价值巨大
- **大多数问题不在模型**：换模型不一定能解决问题，先考虑数据、阈值、前后处理
