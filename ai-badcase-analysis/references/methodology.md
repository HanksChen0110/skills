# Badcase分析方法论

本文档提供AI产品Badcase分析的完整方法论，分为四个部分：认知篇、现状篇、分析篇、解决篇。

---

## 认知篇

### 什么是badcase

Badcase是算法领域术语，指推理阶段产生的与预期不同的结果。例如文本分类任务中，应该分正类却分成了负类。

**重要认知：**
- 即使是人类预测也会因走神、认知差异、知识受限等因素出错
- 模型出现badcase是正常现象
- 不要因为出现badcase就认为模型有问题

### badcase分析的意义

**核心价值：**

1. **症状诊断**：如果模型效果不好是病，badcase就是症状，是问题现场留下的线索。了解badcase能帮助理解问题背后的病因，对症下药。

2. **经验积累**：badcase分析是了解业务、了解场景的重要途径，能发现当前研究和实践中容易出现的问题。

**突破瓶颈：**

当模型理解和吸收出现瓶颈时，多看badcase可以拓展思路。发现的问题多了，自然会产生解决方案，创新点和解决问题的能力也会随之增强。

### badcase分析的心理关

**常见抵触原因：**
1. 数据多，分析枯燥，时间长
2. 不清楚该怎么分析

**解决方案：**
- **数量控制**：50-100条即可说明问题。文本分类500条标注约10分钟，分析100条badcase也约10多分钟，时间成本可控。
- **价值认知**：分析完可以触摸到问题根本，提升问题理解，收获很大。

---

## 现状篇

### 什么是现状

现状即baseline方案在评测集上的效果表现：好or不好，是否需要优化，哪个方面需要优化。只有明确宏观现状，才能确定下一步动作。

**关键原则：必须先明确现状，才能确定优化方向。不要发现一个badcase就立即修复。**

### 现状定位第一步：评测集

评测集是测试算法方案的"试卷"，需要满足三个条件：

#### 1. 完整意义的数据集

不能用一两条case断定方法好坏。要综合评定，需要具有一定数量的数据集。

#### 2. 具有统计意义

**数量要求：**
- 数量足够支撑指标计算稳定
- 1条数据误差100%，100条误差仅1%
- 结合实际使用需求确定可靠数量

**抽样要求：**
- 抽样情况与实际使用场景尽可能一致
- 常用方式：用在线随机query构造评测集
- 能在上线前暴露问题，通过频次观测严重程度

#### 3. 质量可靠

**检测方式：**
- 自己标注100条，看是否与预期相同
- 准确率95%以上：非常靠谱
- 准确率90%：勉强可用（仅能支撑准确率85%的方案评测）

**注意事项：**
- 开源数据集（如LCQMC）也可能有标注错误
- 准确率到90%上不去，可能是评测集问题
- 不要为提升几个点而高兴，先检查数据质量

### 现状定位第二步：指标

#### 1. 指标设计考虑观测目标

指标要体现什么现状，这是指标存在的根本。

**示例：**
- 在线关键目标是避免误召回
- 准确率指标：`实际是该意图 / 算法预测该意图正类`
- 负类预测情况可能不关心，可不设计在计算公式里

#### 2. 注重指标口径

数据分析讲究口径，即取数据的条件。不同条件取数据可能得到截然不同的结论。

**示例（多路召回）：**
- 方案A召回的正类准确率是多少
- 方案B召回的准确率是多少
- 所有出错case中，哪一路召回量最大

通过口径切分，快速定位哪个方案出现问题，哪个问题是关键问题。

#### 3. 多个指标组合观测

单独看一个指标可能忽略其他关键问题。

**示例：**
- 准确率能观测误召回情况
- 优化准确率时，召回数量会降低
- 需同时看准确率和召回率，两者平衡提升才健康可靠

### 现状定位第三步：结论

现状确定需要得出结论：算法效果好or不好，是否需要进行优化。

#### 1. 回顾预期目标

- 明确预期，如准召80%+
- 判断结果高低需要预判基准
- 100%难度大，需合理预期

#### 2. 指导后续工作

- 好or不好决定是否进一步优化
- 下结论时要顾及下一步工作

#### 3. 总结优化方向

- 初步结论下可总结大方向：优化准确、扩大召回等
- 具体怎么做在badcase分析时找
- 这一步要有模糊方向，知道哪些badcase是关键

### 小结

现状分析让我们对数据和效果有宏观把握。每个步骤都不能忽略，磨刀不误砍柴工，有这套思路和方法，找问题和分析问题的能力能大幅提升。

---

## 分析篇

### 什么样的badcase适合被分析

结合现状分析，确定要优化的方面（准确率、召回率等），去看影响这些指标的因素：
- 准确率分错的case
- 漏召回的case

**数量要求：**
- 建议50-200个
- 除非发现严重明显bug，否则分析到预定数量再停止
- 少量分析可能影响判断，需有统计意义

**抽样要求：**
- 必须随机抽样
- 非随机可能导致主干问题不出现在样本中

### badcase分析思路

#### 1. 粗看法

**方法：**
- 笼统地看错误样本的共同特点
- 关注长度、句式、问句等特征
- 通篇看下来，总结突出问题

**优缺点：**
- 优点：快速找到大问题
- 缺点：细节问题难发现，深层次原因难探究

**适用场景：**
- baseline刚建立，效果未收敛时非常有用
- 后期收官时不太好用

#### 2. 追溯法

**方法：**
- 对一个case，重现整个训练和预测过程
- 准备日志，分析预测每个阶段的结果
- 查看是否符合预期，不符合预期的部分可能有bug、词典词汇等问题

**模型层面：**
- 去训练样本查找是否含有类似badcase
- 检查正负样本比例是否失衡

**示例：**
- 百科意图中问句被误召回
- 检查训练集中带疑问词的正负样本比例
- 正样本远多于负样本时，模型会认为带疑问词就是正类
- 解决方案：添加带疑问词的负样本，如"为什么你的心情不好"（闲聊类而非百科类）

**特点：**
- 比较繁琐，但从整个过程寻找问题蛛丝马迹
- 要找到单个case的核心原因，这一步几乎不可忽略

#### 3. 解决法

**思路：**
- 反向思考：知道有哪些解决方法，看badcase是否可用这些方式解决
- 把问题归纳到对应解决方案上

**示例：**
- 短句预测不正确，一般较模糊
- 考虑过滤所有短句，通过白名单补召回
- 把query归类为短句问题

### 问题标记

Case需要逐个分析，后续需归纳总结重点问题，因此需要做关键记录：归因、解决方案总结等。

**标记示例：**

| query | 原因分析 |
|-------|----------|
| 关闭 | 短句 |
| 今天天气怎么样 | 疑问词，关键词拒绝 |
| 你为什么 | 疑问词，模糊短句 |
| 什么 | 疑问词 |

**标记注意事项：**
- 词汇和问题统一，方便统计占比
- 一个问题可能有多个解决方法，都要标记
- 统计分析时都要关注

### 问题统计和归纳

有了标记，能轻易看到各问题分布情况。

**示例：**
- 疑问词相关：3个
- 短句相关：2个
- 关键词拒绝：1个
- 模糊：1个

**结论：** 疑问词问题占比最高，需要针对性解决（批量解决）。

**重点问题价值：**
- 重点问题基本是占比高的问题
- 缓解或解决对效果影响巨大
- 准确率60%场景，一个问题占比50%：
  - 完全解决：准确率提升20%
  - 解决50%：准确率提升10%

### 时间问题

- 小则5分钟，多则半小时
- 在解决问题毫无头绪时，花时间定位问题然后针对性解决，思路更清晰
- 大胆去做去分析

### 一些思考

Case分析是算法增长点、创新点的来源。很多时候努力刷sota，是否真正看过前沿方案的badcase是什么样的？如何让它变得更好？思路就是从中一点一点找出来的。

明察秋毫需要观察，badcase就是线索，要突破必须把这块分析清楚。

---

## 解决篇

### 模型预测错误的解决方案

算法工程师的舒适区是模型，但大多数问题不在模型本身。很多问题不是换模型就能解决的，换模型带来的收益可能很小。

#### 1. 样本的误导

**原理：**
从条件概率角度，机器学习模型：`P(Y=y|X=x) = f(x)`

**问题：**
- 数据中浅层直白的信息，模型会预测得非常直白
- 正类有大量含"怎么"的样本，负类没有
- 模型会把所有带"怎么"的句子预测为正类
- 这与模型好坏无关，是数据指导模型学到的

**解决方案：**
- 调整数据，让模型摒弃误导性特征
- 最直接方式：添加带"怎么"的句子到负类数据
- 平衡正负样本关系，告诉模型不能仅根据"怎么"判断正负类

**识别方法：**
- 这是面模型问题的常见情况
- badcase中从句子层面发现明显共性的，大概率是这个问题

#### 2. 阈值的确定和权衡

**本质：**
- 阈值是准入条件
- 本质是准召的权衡
- 模型提供意见，是否采纳通过阈值

**方法：**
- 对标准召做权衡，取舍是肯定的
- 准召本身是一对矛盾概念

**实验数据示例：**

| 阈值 | 准确率 | 召回率 |
|------|--------|--------|
| 0.9  | 0.92   | 0.40   |
| 0.85 | 0.90   | 0.60   |
| 0.80 | 0.85   | 0.75   |
| 0.75 | 0.79   | 0.80   |

**确定原则：**
- 随着阈值下降，准确率下降，召回率上升
- 搜索和对话场景：保准确，一般0.85+，召回率另说持续优化
- 确定最佳阈值（如0.8）

**数据准备：**
- 没有标注数据的，请自行准备
- 必要时只能自己标

#### 3. 前后处理和预处理

**预处理：**
- 本质：对数据进行处理，使之更好地被用来预测
- 不同场景和数据的预处理方式不同
- 共同点：对标点的处理
- 不同点：
  - 对话场景：删除"你好"之类的称呼
  - 语音助手：删除"小爱同学"、"小布"等称呼
- **重点：** 去掉对预测有影响的干扰项、不利于预测的因素
- **如何识别干扰项：** 看badcase，错误样本会告诉你

**前处理：**
- 模型预测之前的处理
- 模型大、性能要求高的场景：过滤能快速预测的内容
- 提升性能，降低模型负担
- **方法：**
  - 简单：黑白名单
  - 复杂：业务规则（超短句、超长句直接拒绝等）
- **原则：** 能用规则尽量用规则，能不用模型尽量不用模型

**后处理：**
- 模型预测后的调整
- **方法：**
  - 阈值过滤
  - 结合模型预测打分调整
  - 关键词抽取：对重要性分数加减分（句首词、句尾词提权）
  - 实体约束：如"五一节的由来"和"六一节的由来"语义相似但实体不同，需过滤
- **本质：** 对模型的修正，模型难学习的东西通过后处理修复
- **规则转样本：** 特定规则可挖掘新样本，批量放入模型，提升泛化能力
- **注意事项：** 词典敏感的规则最好保留，词典可枚举性放到模型需要很多样本

### 解决问题的验证和迭代

**流程：**
1. 重跑验证集，看修复后效果
2. 回到第一步：现状确认
3. 重新确定是否还要优化
4. 如需优化，继续badcase分析
5. 持续优化，螺旋上升

#### 问题的暴露和转移

**核心问题：**
- 已知问题解决不一定带来直接优化
- 根本原因：老问题不解决，新问题暴露不出来
- 随着问题逐步解决，很多问题会从主要问题变成次要问题，新问题会暴露出来

**案例：**
- 推荐论文中很多模型，实验效果好看但用起来效果不明显甚至负向
- 原因：新模型没有解决问题，或解决的问题不是当前核心问题
- 示例：要整用户序列，但用户点击量不够，意义就不大

**启示：**
- 随着学习会有各种工具解决问题
- 如果工具不适用于现在的核心问题，效果就是负向
- 这也是希望大家多去分析的原因之一

**心态：**
- 问题千千万，一山放过一山拦
- 但随着解决，总会朝着目标靠近，持续努力即可

### 什么时候该换模型

**核心观点：**
- 换模型的本质不在提升效果，而是算法系统预测能力上限的提升
- 换模型不一定使效果提升，甚至可能暴露新问题
- 需要持续调教，效果才可能完成新的提升

**换模型时机：**
- 能明显看到当前方案的天花板时
- **天花板标志：**
  - 很多零散的badcase
  - 问题不太能总结出来
  - 总结出来发现分布很均匀，每个只错一两条
  - 此时可能是当前模型吃不下了

**注意事项：**
- SOTA是特定数据集的SOTA，是否适合你要多想想
- 归根结底要做实验
- 靠修补提升不了效果时，才靠模型进一步探索

---

## 总结

本文总结了badcase从定位分析到解决的全流程思路方案，这是一套完整的方法论。

有这套严格的方法论指导，能在分析问题时更加严谨全面，不遗漏细节和关键步骤，也不容易陷入迷茫。

很多东西看似自然但做起来容易忘记，例如现状的确认（好or不好），我们容易忘记去确定这个，发现一个badcase就去修，很可能会导致新问题出现。


































