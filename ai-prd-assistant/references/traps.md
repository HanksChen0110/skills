---
date: 2025-01-XX
---

# AI PRD常见陷阱与避坑指南

## 一、PRD撰写过程中的常见陷阱

### 陷阱1：一次性写完，没有迭代

**❌ 错误做法**：
- 花2周时间写完所有7个部分，然后交给研发
- 认为PRD必须一次性完美

**✅ 正确做法**：
- 先写核心3部分（目标、工作流、异常处理），与研发对齐后再补充细节
- 根据项目阶段选择复杂度，MVP阶段用最小可行PRD即可
- 持续迭代，根据反馈调整

### 陷阱2：过度追求完美

**❌ 错误做法**：
- 每个部分都要写得很详细，导致PRD过于冗长
- 被"7个部分"锚定，认为必须全部写满

**✅ 正确做法**：
- 根据项目阶段选择复杂度（最小可行/标准/完整）
- 在资源有限时，优先保证核心3部分的质量
- 不要为了完整而完整，要为了有用而完整

### 陷阱3：缺乏数据支撑

**❌ 错误做法**：
- 所有判断都基于"我认为"
- 没有参考历史数据或行业基准
- 成本估算、指标定义都是拍脑袋

**✅ 正确做法**：
- 在成本评估、指标定义时，参考类似项目的历史数据
- 使用外部基准，而非仅凭直觉
- 进行"预演"：模拟实际使用场景，看PRD是否覆盖

### 陷阱4：忽略失败场景

**❌ 错误做法**：
- 只描述"理想情况"下的工作流
- 假设AI在所有场景都能完美工作
- 异常处理部分写得过于简单

**✅ 正确做法**：
- 异常处理部分必须详细，考虑各种失败场景
- 必须制作异常情况处理表
- 明确三类场景：确定性、建议性、交互性

### 陷阱5：没有验证机制

**❌ 错误做法**：
- 写完PRD就认为完成了
- 没有设计验证方法
- 没有定义如何评价PRD是否有效

**✅ 正确做法**：
- 在PRD中明确"如何验证这个设计是否有效"
- 定义MAP（最小可接受性能）
- 设计A/B测试、用户反馈等验证方法

### 陷阱6：用传统PRD思维写AI PRD

**❌ 错误做法**：
- 只描述功能，不定义边界
- 用"通过/不通过"的标准评测AI
- 不明确Agent的权限和义务

**✅ 正确做法**：
- 重点描述边界、目标和评价方式
- 用准确率、用户体验评分等指标
- 明确权限、义务、边界、路径

### 陷阱7：把"用大模型写PRD"当成偷懒捷径

**❌ 错误做法**：
- 直接让LLM生成PRD，不思考核心问题
- 认为AI可以替代PM的思考

**✅ 正确做法**：
- 问题定义、边界设定、评估标准需要自己先想透
- 再让工具协助补全和表述
- 30%的时间工作（给材料、调教AI、审核AI），70%的时间学习（思考核心问题）

## 二、PRD评审时的常见盲点

### 盲点1：只看结构，不看逻辑

**问题**：
- 评审者可能只检查"7个部分是否都有"
- 忽略了各部分之间的逻辑一致性

**解决方案**：
- 检查产品目标与Agent人设是否一致
- 检查工作流设计是否支持产品目标
- 检查工具集是否覆盖了工作流的所有需求

### 盲点2：过度关注细节，忽略整体

**问题**：
- 评审者可能纠结于某个工具的参数定义
- 忽略了整体目标是否清晰

**解决方案**：
- 先评审整体目标和逻辑
- 再评审具体细节
- 使用"反证法"：主动寻找可能失败的原因

### 盲点3：缺乏外部视角

**问题**：
- 评审者都是内部人员
- 可能陷入"确认偏误"，只看到支持设计的证据

**解决方案**：
- 邀请外部专家或用户参与评审
- 使用"反证法"：主动寻找可能失败的原因
- 进行"预演"：模拟实际使用场景，看PRD是否覆盖

## 三、反模式（NEVER Do）

### ❌ 反模式1：用传统PRD思维写AI PRD

**错误做法**：只描述功能，不定义边界

**正确做法**：重点描述边界、目标和评价方式

### ❌ 反模式2：忽略不确定性

**错误做法**：假设AI在所有场景都能完美工作

**正确做法**：明确三类场景，设计兜底策略

### ❌ 反模式3：用功能测试用例评测AI产品

**错误做法**：用"通过/不通过"的标准评测AI

**正确做法**：用准确率、用户体验评分等指标

### ❌ 反模式4：Agent型产品不定义权限

**错误做法**：不明确Agent的权限和义务

**正确做法**：明确权限、义务、边界、路径

### ❌ 反模式5：过度自信

**错误做法**：认为"写了PRD就能成功"

**正确做法**：理解PRD的局限性，PRD是降低失败概率的工具，不是成功的保证

### ❌ 反模式6：规划谬误

**错误做法**：过于乐观地估计时间和资源

**正确做法**：参考历史数据，考虑缓冲时间，评估技术复杂度

### ❌ 反模式7：确认偏误

**错误做法**：只看到支持设计的证据，忽略失败场景

**正确做法**：主动寻求反证，考虑失败场景，邀请外部视角

## 四、认知偏差检查

### 过度自信 (Overconfidence)

**检查点**：
- [ ] 是否避免了"写了PRD就能成功"的假设？
- [ ] 是否说明了PRD的局限性？
- [ ] 是否考虑了市场、技术、团队等外部因素？

### 规划谬误 (Planning Fallacy)

**检查点**：
- [ ] 是否参考了类似项目的历史数据？
- [ ] 时间估算是否考虑了缓冲？
- [ ] 是否考虑了技术实现的复杂度？

### 确认偏误 (Confirmation Bias)

**检查点**：
- [ ] 是否主动考虑了失败场景？
- [ ] 是否考虑了反例（什么时候不适用）？
- [ ] 是否邀请了外部视角参与评审？

### 可得性偏差 (Availability Bias)

**检查点**：
- [ ] 是否只关注了最近的、印象深刻的案例？
- [ ] 是否系统性地覆盖了所有场景？
- [ ] 是否考虑了不同行业的差异？

### 基础比率忽视 (Base Rate Neglect)

**检查点**：
- [ ] 是否参考了行业基准数据？
- [ ] 是否使用了统计思维，而非仅凭直觉？
- [ ] 是否考虑了类似项目的成功率？

## 五、快速避坑检查（3分钟版本）

如果时间有限，至少检查这3项：

1. [ ] **是否避免了过度自信**：是否说明了PRD的局限性？
2. [ ] **是否考虑了失败场景**：异常处理是否详细？
3. [ ] **是否定义了验证方法**：如何验证PRD是否有效？

---

**核心原则**：PRD不是理想蓝图，而是现实约束下的最佳实践。不仅要告诉你怎么做，更要帮你避免常见错误。





































