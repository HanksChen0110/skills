---
date: 2025-12-03
---

# AWS提示词工程16种方式

> 来源：AWS官方博客《充分释放大模型的潜力——提示词工程的16种方式》

## 整体框架

### 预训练 / 微调 / 提示词工程

- **预训练（Pre-training）**：在大规模无标注语料上自监督学习，获得通用语言理解与生成能力
- **微调（Fine-tuning）**：用有标注任务数据对预训练模型进行再次训练，适配特定任务场景
- **提示词工程（Prompt Engineering）**：不改模型参数，仅通过设计提示调用模型内部已有知识

**提示词工程优势**：轻量、高效、灵活，可快速试错与迭代

## 五大类型总览

1. **直接提示（Prompt）**：更多在"怎么问"和"补充什么知识"
2. **链式提示（Chain）**：更多在"怎么推理"和"怎么组织推理结构"
3. **图谱提示（Graph）**：结构化思维 + 图结构推理
4. **生成类提示（Generate）**：先生成中间知识，再辅助决策
5. **集成式提示（Integrate）**：更多在"怎么接入外部资源和工具"

## 一、直接提示（Prompt）

### 1. Zero-shot（零样本提示）
只给指令，不给示例。

**适用**：简单任务、通用问题、快速探索

**示例**："我该怎么表白？"

### 2. Few-shot（少样本提示）
在指令里追加1–N个高质量示例，让模型"模仿模式"。

**适用**：需要固定格式、固定风格或较稳定输出结构的任务

**示例**："这是几个例子，如何模仿这些例子对她表白？" + `<example>...</example>`

### 3. Act提示（角色扮演/指定身份）
明确指定模型扮演的角色、场景、语气。

**适用**：需要特定视角（专家、导师、审稿人等）的回答

**示例**："你是一位擅长恋爱沟通的心理咨询师，请帮我设计一段表白文案……"

### 4. ReAct（Reason + Act，反应式提示）
结构化地让模型在"思考（Reason）"和"行动（Act）"之间来回迭代。

**关键点**：外部信息反馈 → 模型归因 → 再输出新动作或新回答

**示例**："初始表白方案 → 她的反应 → 让模型根据反馈调整下一步行动"

### 5. Directional Stimulus Prompting（方向性刺激提示）
在提示词中加入"约束/方向性提示"，限制模型在特定领域或视角内生成。

**对比标准提示**：
- 标准提示：开放生成，容易发散
- 方向性刺激：在特定子空间内搜索，让输出更聚焦

**示例**："她喜欢哲学，我该怎么在表白的时候引入相关内容？"

## 二、链式提示（Chain）

### 6. 思维链（Chain-of-Thought, CoT）
显式要求模型"逐步思考"而不是直接给答案。

**典型指令**："请一步步地展示你的推理过程"

**好处**：复杂算术、逻辑推理、场景规划类问题精度大幅提升

**示例（算术题拆解）**：
- 题目："我有23个苹果，吃了20个后又买了6个，现在还有几个？"
- CoT步骤：
  1. 开始有23个
  2. 吃掉20个 → 剩3个
  3. 又买6个 → 3 + 6 = 9
  4. 答案：9个

### 7. 自洽（Self-consistency）
让模型**多次**独立思考/生成多条CoT，然后从中选取最一致或最合理的答案。

**思路**：用"投票 + 多样推理路径"提升稳定性与准确率

### 8. 思维树（Tree-of-Thought, ToT）
不只是一条线性思路，而是**多条推理路径**并行探索。

**模型会**：
- 分支出不同假设/解法
- 再从中筛选、评估、聚合出更优解

**适合**：开放式问题、复杂规划、多解空间任务

**示例**："我需要为我的新咖啡馆想一个独特的营销方案，并且预算有限。请你扮演三位不同的营销专家。第一位专家专注于社交媒体，第二位专注于本地社区活动，第三位专注于数字广告。请你们各自提出一个初步的核心想法。然后，互相评估对方想法的优缺点。最后，综合所有讨论，给出一个融合了最佳元素的最终营销方案，并解释为什么这个方案最好。"

### 9. 自我反思（Reflexion）
让模型对自己的初次回答进行：复盘、找错、修正

**操作方式**：
1. 第一次回答问题
2. 第二轮让模型审视/批改自己
3. 生成改进版答案

### 10. 多模态思维链
在CoT思路基础上，把图片、表格等多模态信息也纳入推理链条。

**适合**：图表解读、多模态理解与决策

## 三、图谱提示（Graph）

### 11. 知识图谱提示（Knowledge-Graph-based Prompting）
构建"知识图谱"：节点为概念、实体、步骤；边为因果关系、先后顺序、依赖关系。

让模型在图结构中沿路径推理，对不同路径进行比较与选择。

**适用场景**：复杂业务流程（如供应链、金融、医疗）

### 12. 任务图提示（Task-Graph / Workflow Prompting）
基于任务图/流程图的提示，适用于多步骤依赖任务（如规划、排程、诊断）。

## 四、生成类提示（Generate）

### 13. 生成知识提示（Generate Knowledge Prompting）
在回答问题前，先让模型生成一段相关知识或背景说明，再基于这段知识回答。

**示例流程**：
1. 输入问题 + "请先写出与此相关的知识点，然后再回答"
2. 模型先输出"知识：……"
3. 再输出"解释和答案：……"

**文章示例（高尔夫球）**：
- 问："高尔夫球的一部分是试图获得比其他人更高的得分。是或否？"
- 生成知识："高尔夫球的目标是以最少的杆数打完一组洞……"
- 得出结论："不是，高尔夫球的目标不是获得更高得分，而是更少杆数。"

### 14. 生成-阅读模式（Generate-then-Read / Generate-then-Reason）
先生成：关键词、提纲、候选方案、反例等，再让模型"阅读自己的产物"并据此做出判断或选择。

**适合**：需要多角度分析的任务（如评估、对比、批改、策略制定）

**通用要点**：通过"先生成、再使用"的方式，让模型调动更多内部知识

## 五、集成式提示（Integrate）

### 15. RAG：检索增强生成（Retrieval-Augmented Generation）
**核心流程**：
1. 通过向量检索/关键字检索，从知识库中取回相关文档
2. 把检索结果与用户问题一起作为提示，交给LLM生成答案

**优点**：用最新、领域专有知识增强模型能力，避免完全依赖模型参数中的"旧知识"

### 16. 工具使用 & 程序辅助（Tool Use / Function Calling & PAL）

**工具使用**：通过函数调用/工具调用的方式，让模型能查数据库、调接口、读写文件、操作系统/第三方应用。

**程序辅助语言模型（PAL）**：把一部分严谨逻辑/计算交给传统程序（例如Python代码），模型负责生成代码、解释结果。

**优点**：对于算术、符号推理、结构化任务更可靠

**自动推理（Agent）**：大模型作为"大脑"，自动拆解任务、决定调用哪个工具或子模块、规划执行顺序。

## 综合案例：Text2SQL架构

综合使用了多种提示与技术：

1. **意图识别与非法输入过滤**：通过提示词+模型判断用户输入是否合法
2. **RAG**：基于知识库检索相似SQL，作为few-shot示例输入给大模型
3. **大模型生成目标SQL**：利用相似SQL和自然语言问题，让模型生成最终SQL语句
4. **程序辅助（PLA）**：执行SQL → 获得结果集 → 调用可视化或分析程序生成图表、洞察

该架构本质上是：
- **直接提示（Prompt）**：问题 + 角色 + 约束
- **生成类提示（Generate）**：基于示例生成SQL
- **集成式提示（Integrate）**：RAG + 工具调用 + 程序辅助

## 实践落地建议

1. **从简单到复杂，逐步升级**
   - 先掌握：Zero-shot / Few-shot / Act
   - 再引入：CoT / 自洽 / Reflexion
   - 然后尝试：RAG + 工具调用 + 程序辅助

2. **将"任务"拆成3个层面**
   - **外部提示**：问题描述、角色、格式要求（Prompt）
   - **内部推理**：思维链/思维树/图谱（Chain & Graph）
   - **外部资源**：知识库、数据库、API、代码（Integrate）

3. **持续迭代提示词**
   - 把有效提示沉淀成：模板、SOP、可复用片段
   - 与自己的业务场景结合

