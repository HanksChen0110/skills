---
name: agent-builder-assistant
description: 帮助搭建AI Agent的技能助手。当用户说「搭建Agent」「创建Agent」「Agent搭建」「智能体搭建」「设计AI系统」时使用。提供Agent核心哲学、四要素、六大核心要素、工作流搭建心法、RAG详解、Prompt工程等完整方法论。适用于AI Agent开发、智能体构建、工作流设计、自主AI系统开发。
---

# AI Agent 搭建助手

## 核心哲学

> **The model already knows how to be an agent. Your job is to get out of the way.**

**关键洞察**：模型本身就是 agent。代码只是运行循环，提供让模型行动的机会。

Agent 不是复杂的工程，而是一个简单的循环：

```
LOOP:
  Model sees: context + available capabilities
  Model decides: act or respond
  If act: execute capability, add result, continue
  If respond: return to user
```

**That's it.** 魔法不在代码里，而在模型里。你的代码只是提供机会。

## 概述

本技能提供AI Agent搭建的完整方法论，从哲学思维到实践技术，涵盖Agent核心哲学、四要素、六大核心要素、工作流搭建心法、RAG技术、Prompt工程等核心知识。

## Agent 四要素

### 1. 思考：大模型
Agent的核心能力来源，什么环节用什么LLM，需要综合考虑节能、输出效率、输出效果等多方面因素。
- 以及怎么激活大模型的能力（prompt），提示词工程

### 2. 规划：反射、自我反思、思维链、子目标拆解
- 工作流

### 3. 记忆：长期/短期记忆，上下文记忆，知识库

### 4. 执行：调用工具、使用技能

## 三个核心元素（哲学视角）

### 1. Capabilities (What can it DO?)

原子级动作，agent可以执行的操作：搜索、读取、创建、发送、查询、修改。

**设计原则**：
- 从3-5个能力开始
- 只有当agent因为缺少某个能力而持续失败时，才添加更多
- 每个能力应该是原子的、清晰的、描述良好的

**常见错误**：能力太多。模型会困惑，开始使用错误的能力，或因选择过多而瘫痪。

### 2. Knowledge (What does it KNOW?)

按需注入的领域专业知识：政策、工作流、最佳实践、模式。

**设计原则**：
- 让知识可用，而非强制
- 在相关时加载，而非预先加载
- 渐进式披露，保护上下文清晰度

**常见错误**：预先加载所有可能的知识。这会浪费上下文，混淆模型，使每次交互都变得昂贵。

### 3. Context (What has happened?)

对话历史——将行动连接成连贯行为的线索。

**设计原则**：
- 上下文是珍贵的。隔离产生噪音的子任务
- 截断冗长的输出
- 保护清晰度

**常见错误**：让上下文无限增长，填充探索细节、失败尝试和冗长的工具输出。最终模型无法在噪音中找到信号。

## 智能体构建的六大核心要素

1. **大模型**：如何去选择合适的大模型来生成适合这个环节的内容，如何对大模型进行合适的设置
2. **提示词工程**：如何撰写和使用优秀的提示词发挥大模型的能力
3. **工作流**：如何用工作流将业务完整和准确的复现
4. **技能/工具**：如何选择合适的技能和正确的工具
5. **知识库**：如何构建更健壮和准确的知识库，提升回答准确度
6. **上下文记忆**：如何配置上下文记忆，让模型能够响应个性需求

## Agent 设计思维

在构建之前，理解：

- **Purpose**: 这个agent应该完成什么？
- **Domain**: 它在什么世界中运行？（客户服务、研究、运营、创意...）
- **Capabilities**: 哪些3-5个动作是必需的？
- **Knowledge**: 它需要访问哪些专业知识？
- **Trust**: 你可以将哪些决策委托给模型？

**关键原则**：信任模型。不要过度工程化。不要预先指定工作流。给它能力，让它推理。

## 工作流搭建心法

### 心法口诀

从简单到复杂，
从动脑到行动，
从单点到流程，
从随机到可控，
从手动到自动。

### 工作流搭建的学习方法

**实践先行的学习路径**：
- 成年人学习很多事情都是先从实践中学习，从0到1先做一坨垃圾出来，然后再去慢慢优化
- 解决问题的过程本身就是学习，解决掉一个问题就会成长一些，与目标中间的模糊就更少一些

**理论与实践的结合**：
- 但是光是只会搭一些60分的作品出来肯定不够
- 前面做东西可以先实践再学，但最终还是需要再返回去学习理论知识，这样才能充分理解并创造真正有价值的东西

## 渐进式复杂度

从简单开始。只有在实际使用揭示需求时才添加复杂度：

| Level | 添加什么 | 何时添加 |
|-------|---------|---------|
| **Basic** | 3-5个能力 | 总是从这里开始 |
| **Planning** | 进度跟踪 | 多步骤任务失去连贯性时 |
| **Subagents** | 隔离的子agent | 探索污染上下文时 |
| **Skills** | 按需知识 | 需要领域专业知识时 |

**大多数agent永远不需要超过Level 2。**

### 渐进式复杂度层级

```
Level 0: 模型 + 一个能力
Level 1: 模型 + 3-5个能力
Level 2: 模型 + 能力 + 规划
Level 3: 模型 + 能力 + 规划 + 子agent
Level 4: 模型 + 能力 + 规划 + 子agent + 技能
```

从可能工作的最低级别开始。只有在实际使用揭示需求时才向上移动。

## AI架构沙盘

在思考一个AI如何架构时，可采用以下维度：

### 基础设施：算力来源/算力大小/算力能耗
- 算力来源决定部署方式，本地还是云端
- 算力大小决定并发，计算的响应速度等
- 算力能耗主要体现在本地集中部署的时候

### 模型：模型能力-模型选型/本地（微调要怎么做）or在线

**核心思想**：选择合适的大模型最重要的就是验证AI擅不擅长做你想他做的事

**模型选择示例**：
- 需要长文本时，选择Kimi K2模型
- 需要深度思考有质量的输出时，选择现在深度思考更强的Deepseek或者豆包1.6等
- 需要文生图时，选择Nano Banana Pro或者MJ或者Seedream4等
- 需要视频制作时，用Sora或者即梦等

**本地化与微调**：
- 如果对本地化有要求，可以用ollama把模型拉到本地来使用
- 可以用火山方舟/阿里云百炼/百度千帆等工具对模型进行微调

### 数据：数据来源/数据清洗/增强

**数据来源**：可以是实时网络搜索/企业自有的数据库/飞书云文档/各种表格/图片等

**数据清洗**：可以用阿里云百炼进行测试验证

**变量**：用来存储动态变化的数据，使Agent可以根据不同的情况进行灵活调整

### 提示词：prompt工程-激发LLM能力

**内容表达**：话在嘴边说不出来，我的知识/认知盲区。这两者都只有自己去多练习多感悟才能从中获得经验与体会
- 表达力的本质是用最准确的语言调动对方的===理解力===和===执行力===

**形式技巧**：
- 一阶-三板斧：角色/任务/输出
- 二阶-魔法棒：用魔法打败魔法
- 三阶-结构化：追求复用和稳定
- 四阶-分治法：分而治之单点击破

**创作过程**：解构-建构-压缩-表达

## RAG（检索增强生成）详解

### RAG的关键概念

- 引用数量
- 关键词检索
- 向量检索
- 混合检索
- 混合相似度阈值
- 关键词相似度权重

### RAG的过程

**分块策略**

**Embedding文本转向量**：
- 有专门的Embedding模型
- 输入文本→分词→Embedding模型处理→生成向量→存到向量数据库→查询与检索

**检索过程**：根据向量数据库中对应数据的权重分布，匹配对应的数据

**搜索类型**：
- 语义检索
- 全文检索
- 混合检索（全文/语义检索）

**搜索阶段**：
- 粗排阶段：剔除不符合条件的文本，返回第一阶段检索结果
- 精排阶段：根据粗排结果做相似度计算，得出符合条件的文本结果

**召回策略**：
- 自动调用：调用知识库并使用召回的内容辅助生成回复
- 按需调用：根据提示词自行判断是否调用，并使用召回内容辅助生成

**查询改写**：联系上下文来生成回复

**ReRank结果重排**：根据用户的输入将得出的文本按照权重从高到低展示给用户

### RAG调优

- 当待检索文本中包含大量相似性文本时：可适当提高【混合相似度阈值】，以检索出相似度更高的文本段
- 当用户希望使用关键词过滤文本时，可使用【关键词检索】；希望用语义去检索文本时，可使用【向量检索】
- 当用户的问题中与文档更多的是关键词联系，关键词少且精：可以提高【关键词相似度权重】，或者尝试使用【关键词检索】
- 当用户的问题和文档内容很明显没有关键词联系，但是有意思相近的部分，尽量使用【向量检索】，或者降低【关键词相似度权重】
- 当知识库设置的语言是非英语的外语时，默认使用【向量检索】且不可更改

### 传统RAG vs Agentic RAG

- **传统RAG**：就像图书管理员，你要什么就去知识库里找到然后给你（搜一下然后补进这次的生成里面）
- **Agentic RAG**：会按照Agent的一系列操作（思考、规划、记忆、工具）等来辅助这一次的搜索尽可能符合用户的需求，这里面就还涉及到了意图识别、对抗校准等一系列复杂设定

## 提示词Prompt工程

### 什么是prompt工程

prompt工程是专注于用自然语言开发、设计和优化提示，以增加LLM的输出，提供一种引导模型的行为从而达到实现用户期望的方法。

### 有什么好处

- 可以提高模型的能力，增强安全性和稳定性
- 可以使用领域知识和外部工具增强模型，无需更改模型参数或进行微调
- 通过更高质量的输入获得更高质量的输出

### 提示的要素

- **指令**：LLM需要执行的任务
- **上下文**：用于引导模型的外部信息
- **输入数据**：需要响应的输入
- **输出指示**：输出类型或格式

### 最佳实践要素

- 简明扼要：自然流畅，语句连贯，避免孤立的关键字和短语
- 必要时提供上下文
- 针对适当的响应类型使用相应的指令：对输出结果的类型进行约束
- 在提示中考虑输出：使模型专注于输出适当的内容
- 以疑问句开始提示
- 提供示例响应
- 分解复杂的任务
- 反复尝试并发挥创意

### 如何选择合适的prompt策略

- **嵌入式搜索RAG**：需要特定的、最新的或非公开的知识。基于嵌入的搜索，RAG
- **零样本**：不需要特定的、最新的或非公开的知识。任务简单明了，不需要多个例子来来说明。使用单一、清晰的提示，不提供示例，直接要求LLLM做出回应
- **少样本**：任务复杂，需要多个例子来来说明但不需要专门的技能、风格或模式，采用少样本提示的方式，在提示词中为LLM提供几个例子引导其回答
- **微调**：任务复杂，需要多个例子来来说明；需要专门的技能、风格或模式，则需要进行微调，在特定领域、技能或风格的训练集上微调LLM

## 领域示例

**Business**: CRM查询、邮件、日历、审批
**Research**: 数据库搜索、文档分析、引用
**Operations**: 监控、工单、通知、升级
**Creative**: 资产生成、编辑、协作、审查

模式是通用的。只有能力会改变。

## 核心原则

1. **模型就是agent** - 代码只是运行循环
2. **能力启用** - 它能做什么
3. **知识告知** - 它知道如何做
4. **约束聚焦** - 限制创造清晰度
5. **信任解放** - 让模型推理
6. **迭代揭示** - 从最小开始，从使用中演进

## Agent 思维转变

**从**: "我如何让系统做X？"
**到**: "我如何让模型能够做X？"

**从**: "当用户说Y时应该发生什么？"
**到**: "哪些能力可以帮助解决Y？"

**从**: "这个任务的工作流是什么？"
**到**: "模型需要什么来找出工作流？"

最好的agent代码几乎是无聊的。简单的循环。清晰的能力定义。干净的上下文管理。魔法不在代码里——它在模型里。

## 工作流程

### 步骤1：设计思维

**判断问题**：
- Purpose：这个agent应该完成什么？
- Domain：它在什么世界中运行？
- Capabilities：哪些3-5个动作是必需的？
- Knowledge：它需要访问哪些专业知识？
- Trust：你可以将哪些决策委托给模型？

**输出**：Agent设计文档

### 步骤2：选择复杂度级别

**判断问题**：
- 这是单步骤还是多步骤任务？
- 是否需要探索（可能污染上下文）？
- 是否需要领域专业知识？

**选择级别**：
- Level 0-1：大多数情况
- Level 2：多步骤任务
- Level 3-4：复杂场景

### 步骤3：实现核心循环

**基本循环**：
```
LOOP:
  Model sees: context + available capabilities
  Model decides: act or respond
  If act: execute capability, add result, continue
  If respond: return to user
```

### 步骤4：配置能力

**设计原则**：
- 从3-5个能力开始
- 每个能力应该是原子的、清晰的、描述良好的
- 只有当agent因为缺少某个能力而持续失败时，才添加更多

### 步骤5：配置知识

**设计原则**：
- 让知识可用，而非强制
- 在相关时加载，而非预先加载
- 渐进式披露

### 步骤6：保护上下文

**设计原则**：
- 隔离产生噪音的子任务
- 截断冗长的输出
- 保护清晰度

## 反模式（NEVER Do）

### ❌ 反模式1：过度工程化

**错误做法**：在需要之前就构建复杂性
**正确做法**：从简单开始，从使用中演进

### ❌ 反模式2：能力太多

**错误做法**：一开始就提供20个能力
**正确做法**：从3-5个能力开始，只在需要时添加

### ❌ 反模式3：刚性工作流

**错误做法**：预先指定每个步骤的工作流
**正确做法**：让模型决定，给它能力让它推理

### ❌ 反模式4：预先加载知识

**错误做法**：将所有可能的知识加载到系统提示中
**正确做法**：让知识可用但非强制，按需加载

### ❌ 反模式5：微观管理

**错误做法**：试图控制模型的每个决策
**正确做法**：信任模型，让它推理

### ❌ 反模式6：只学形不学神

**错误做法**：跟着教程搭案例，但不知道为什么这么做
**正确做法**：理解"why和how"，把流程跑通，把原理弄明白

### ❌ 反模式7：追求一次性完美

**错误做法**：想要一次性做到完美
**正确做法**：从0到1先做出来，哪怕不完美，然后慢慢优化

### ❌ 反模式8：忽略理论回归

**错误做法**：只会搭一些60分的作品，不返回学习理论
**正确做法**：实践后返回去学习理论知识，充分理解并创造真正有价值的东西

### ❌ 反模式9：模型选择不当

**错误做法**：不验证AI擅不擅长做你想他做的事
**正确做法**：选择合适的大模型最重要的就是验证AI擅不擅长做你想他做的事

### ❌ 反模式10：RAG调优不当

**错误做法**：不根据实际情况调整RAG参数
**正确做法**：根据文本相似性、关键词联系等实际情况调整混合相似度阈值、关键词相似度权重等参数

## 何时读取参考资料

如需查看完整的Agent搭建方法论文档（包含更多细节、平台对比、评估方法等），可读取：
- `references/methodology.md` - 完整的Agent搭建方法论文档
- `references/agent-philosophy.md` - Agent哲学深度解析

如需查看代码示例和模板，可读取：
- `references/minimal-agent.py` - 完整的工作agent示例（~80行）
- `references/tool-templates.py` - 能力定义模板
- `references/subagent-pattern.py` - 上下文隔离模式

如需生成新agent项目，可使用：
- `scripts/init_agent.py` - 生成新agent项目脚手架

## 使用示例

**用户**："帮我搭建一个智能客服Agent"

**响应流程**：
1. **设计思维**：
   - Purpose：处理客户咨询和问题
   - Domain：客户服务
   - Capabilities：搜索知识库、查询订单、创建工单、发送邮件
   - Knowledge：公司政策、产品信息、常见问题
   - Trust：让模型决定何时转人工
2. **选择级别**：Level 1（3-5个能力）
3. **实现循环**：基本agent循环
4. **配置能力**：定义4个核心能力
5. **配置知识**：按需加载知识库
6. **保护上下文**：隔离复杂查询，截断冗长输出
